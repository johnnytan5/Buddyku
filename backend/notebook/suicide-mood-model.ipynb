{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8c0e6c",
   "metadata": {},
   "source": [
    "# Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25dda8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef7938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 64 \n",
    "EPOCHS = 10 # testing purposes\n",
    "NUM_CLASSES = 4 # remapped to 4 instead of 7 classes\n",
    "CLASS_LABELS = [\"Negative\", \"Positive\"]  \n",
    "\n",
    "# dataset directory\n",
    "train_dir = \"./data/train\"\n",
    "val_dir = \"./data/val\"\n",
    "test_dir = \"./data/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a26490bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing model file: suicide_mood_model.keras\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "model_path = \"suicide_mood_model.keras\"\n",
    "\n",
    "# Delete existing model if it exists\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(f\"Removed existing model file: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ea81f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccaa9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation split\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "split_ratio = 0.2\n",
    "\n",
    "for class_name in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    val_count = int(len(images) * split_ratio)\n",
    "    val_images = images[:val_count]\n",
    "    train_images = images[val_count:]\n",
    "\n",
    "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "\n",
    "    for img in val_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(val_dir, class_name)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34cda9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label remapping for binary classification\n",
    "def remap_labels(ori_label):\n",
    "    mapping = {\n",
    "        \"fearful\": \"Negative\",  \n",
    "        \"sad\": \"Negative\",      \n",
    "        \"happy\": \"Positive\"     \n",
    "    }\n",
    "    return mapping.get(ori_label, \"Negative\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6cfd56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16142 images belonging to 3 classes.\n",
      "Found 3228 images belonging to 3 classes.\n",
      "Found 4045 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def relabel_generator(generator):\n",
    "    while True:\n",
    "        batch = next(generator)\n",
    "        if len(batch) != 2:  # Check if batch is properly structured\n",
    "            raise ValueError(f\"Expected batch to be (x,y) but got: {batch}\")\n",
    "            \n",
    "        x, y = batch\n",
    "        y_idx = np.argmax(y, axis=1)\n",
    "        new_labels = []\n",
    "        \n",
    "        for idx in y_idx:\n",
    "            try:\n",
    "                ori_label = list(generator.class_indices.keys())[idx]\n",
    "                new_label = remap_labels(ori_label)\n",
    "                new_labels.append(CLASS_LABELS.index(new_label))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing label idx {idx}: {e}\")\n",
    "                # Default to neutral class if there's an error\n",
    "                new_labels.append(CLASS_LABELS.index(\"Neutral\"))\n",
    "                \n",
    "        y_new = tf.keras.utils.to_categorical(new_labels, num_classes=NUM_CLASSES)\n",
    "        yield x, y_new\n",
    "\n",
    "# Recreate generators\n",
    "train_relabeled = relabel_generator(train_generator)\n",
    "val_relabeled = relabel_generator(val_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fd574b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration saved to model_config.txt\n"
     ]
    }
   ],
   "source": [
    "# Save model configuration for reference\n",
    "model_config = {\n",
    "    \"input_shape\": IMG_SIZE + (3,),\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"class_labels\": CLASS_LABELS\n",
    "}\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"model_config.txt\", \"w\") as f:\n",
    "    for key, value in model_config.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "print(\"Model configuration saved to model_config.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d9229",
   "metadata": {},
   "source": [
    "# Model init + training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f499192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the output layer for binary classification\n",
    "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet', alpha=0.35)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=IMG_SIZE + (3,))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)  \n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4211800",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9852af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train directory...\n",
      "Checking validation directory...\n",
      "Checking test directory...\n",
      "No corrupted images found. Issue might be with file access or permissions.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def find_corrupted_images(directory):\n",
    "    corrupted = []\n",
    "    \n",
    "    for class_dir in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Try to load the image and verify it\n",
    "                        img.verify()\n",
    "                        # If you want to make sure it can be loaded as an array too:\n",
    "                        img = Image.open(img_path).convert('RGB')\n",
    "                except Exception as e:\n",
    "                    corrupted.append((img_path, str(e)))\n",
    "    \n",
    "    return corrupted\n",
    "\n",
    "# Check all directories\n",
    "print(\"Checking train directory...\")\n",
    "train_corrupted = find_corrupted_images(train_dir)\n",
    "print(\"Checking validation directory...\")\n",
    "val_corrupted = find_corrupted_images(val_dir)\n",
    "print(\"Checking test directory...\")\n",
    "test_corrupted = find_corrupted_images(test_dir)\n",
    "\n",
    "# Print results\n",
    "if train_corrupted or val_corrupted or test_corrupted:\n",
    "    print(f\"Found {len(train_corrupted) + len(val_corrupted) + len(test_corrupted)} corrupted images:\")\n",
    "    for path, err in train_corrupted + val_corrupted + test_corrupted:\n",
    "        print(f\"- {path}: {err}\")\n",
    "else:\n",
    "    print(\"No corrupted images found. Issue might be with file access or permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f796e29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corrupted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to remove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m remove_corrupted_files(\u001b[43mtrain_corrupted\u001b[49m \u001b[38;5;241m+\u001b[39m val_corrupted \u001b[38;5;241m+\u001b[39m test_corrupted)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_corrupted' is not defined"
     ]
    }
   ],
   "source": [
    "def remove_corrupted_files(file_list):\n",
    "    for file_path, _ in file_list:\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to remove {file_path}: {e}\")\n",
    "            \n",
    "remove_corrupted_files(train_corrupted + val_corrupted + test_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "628214a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counting images in directories:\n",
      "Class angry: 3995 images\n",
      "Class disgusted: 436 images\n",
      "Class fearful: 4097 images\n",
      "Class happy: 7215 images\n",
      "Class neutral: 4965 images\n",
      "Class sad: 4830 images\n",
      "Class surprised: 3171 images\n",
      "Total images in ./data/train: 28709\n",
      "Class angry: 799 images\n",
      "Class disgusted: 87 images\n",
      "Class fearful: 819 images\n",
      "Class happy: 1443 images\n",
      "Class neutral: 993 images\n",
      "Class sad: 965 images\n",
      "Class surprised: 634 images\n",
      "Total images in ./data/val: 5740\n",
      "Class angry: 958 images\n",
      "Class disgusted: 111 images\n",
      "Class fearful: 1024 images\n",
      "Class happy: 1774 images\n",
      "Class neutral: 1233 images\n",
      "Class sad: 1247 images\n",
      "Class surprised: 831 images\n",
      "Total images in ./data/test: 7178\n"
     ]
    }
   ],
   "source": [
    "# Add this code to check image counts\n",
    "def count_images_in_directory(directory):\n",
    "    total = 0\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            total += len(files)\n",
    "            print(f\"Class {class_name}: {len(files)} images\")\n",
    "    print(f\"Total images in {directory}: {total}\")\n",
    "    return total\n",
    "\n",
    "print(\"\\nCounting images in directories:\")\n",
    "train_count = count_images_in_directory(train_dir)\n",
    "val_count = count_images_in_directory(val_dir)\n",
    "test_count = count_images_in_directory(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622eb6ab",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5337730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 2s/step - accuracy: 0.6147 - loss: 0.6981 - val_accuracy: 0.7175 - val_loss: 0.5767 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.6941 - loss: 0.5860 - val_accuracy: 0.7714 - val_loss: 0.5179 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.7236 - loss: 0.5556 - val_accuracy: 0.7785 - val_loss: 0.4846 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.7343 - loss: 0.5321 - val_accuracy: 0.7878 - val_loss: 0.4620 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.7345 - loss: 0.5301 - val_accuracy: 0.7890 - val_loss: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 1s/step - accuracy: 0.7481 - loss: 0.5231 - val_accuracy: 0.7909 - val_loss: 0.4592 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 1s/step - accuracy: 0.7511 - loss: 0.5134 - val_accuracy: 0.7940 - val_loss: 0.4462 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.7538 - loss: 0.5095 - val_accuracy: 0.7757 - val_loss: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 1s/step - accuracy: 0.7623 - loss: 0.5021 - val_accuracy: 0.7903 - val_loss: 0.4507 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7632 - loss: 0.4952\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - accuracy: 0.7632 - loss: 0.4952 - val_accuracy: 0.7794 - val_loss: 0.4551 - learning_rate: 0.0010\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "callbacks = [early_stopping, lr_scheduler]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_relabeled,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=val_relabeled,\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Delete existing model if it exists\n",
    "if os.path.exists(\"suicide_mood_model.keras\"):\n",
    "    os.remove(\"suicide_mood_model.keras\")\n",
    "    print(f\"Removed existing model file: suicide_mood_model.keras\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"suicide_mood_model.keras\")\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
